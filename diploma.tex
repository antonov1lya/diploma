\documentclass[a4paper,14pt]{extarticle}
\usepackage{graphicx}

\usepackage[left=2.5cm,right=1cm,top=2cm,bottom=2cm]{geometry}

\usepackage[russian]{babel}

\usepackage{amsmath,amssymb,amsfonts}
\usepackage{amsthm}
\usepackage{hyperref}

\theoremstyle{definition}
\newtheorem{definition}{Определение}[section]
\newtheorem{theorem}{Теорема}[section]
\newtheorem{example}{Пример}[section]
\newtheorem{lemma}{Лемма}[section]

\def\ci{\perp\!\!\!\perp}
\usepackage{xcolor}

\begin{document}

\section{Введение}

\begin{definition}
    Случайный вектор $(X,Y,Z)^T$ имеет трехмерное распределение Бернулли,
    если множество его возможных значений
    $$
        \begin{pmatrix}
            0 \\
            0 \\
            0
        \end{pmatrix},
        \begin{pmatrix}
            0 \\
            0 \\
            1
        \end{pmatrix},
        \begin{pmatrix}
            0 \\
            1 \\
            0
        \end{pmatrix}, \ldots, \begin{pmatrix}
            1 \\
            1 \\
            1
        \end{pmatrix}
    $$ и заданы вероятности
    $$P(X=x,Y=y,Z=z)=p_{xyz} \geq 0, \quad \sum_{x=0}^{1}\sum_{y=0}^{1}\sum_{z=0}^{1}p_{xyz}=1$$
\end{definition}

\begin{definition}
    Пусть $(X,Y,Z)^T$ -- дискретный случайный вектор.
    Говорят, что случайные величины $X$ и $Y$ условно независимы при условии $Z$,
    и пишут $X \ci Y \mid Z$, если
    для любых $x,y$ и $z$, такого что $P(Z=z)>0$, выполнено:
    $$
        P(X=x, Y=y \mid Z = z) = P(X=x \mid Z = z) P(Y=y \mid Z = z)
    $$
\end{definition}

\begin{theorem}\label{thm1}
    Пусть $(X,Y,Z)^T$ -- случайный вектор, имеющий трехмерное распределение Бернулли, и $P(Z=0)>0$.
    Случайные величины $X$ и $Y$ условно независимы при условии $Z$ тогда и только тогда, когда
    $p_{00z}p_{11z}=p_{01z}p_{10z}$, где $z=0,1$.
\end{theorem}

\begin{proof}
    Пусть $X \ci Y \mid Z$. Значит, для любых $x=0,1$, $y=0,1$ и $z=0,1$ выполнено условие:
    $$
        P(X=x, Y=y \mid Z = z) = P(X=x \mid Z = z) P(Y=y \mid Z = z)
    $$
    После домножения на $P(Z=z)^2$ получаем эквивалентное условие:
    $$
        P(X=x,Y=y,Z=z)P(Z=z)=P(X=x,Z=z)P(Y=y,Z=z)
    $$
    Найдем маргинальное распределение случайной величины $Z$:
    $$
        P(Z=z)=\sum_{x=0}^{1} \sum_{y=0}^{1} p_{xyz} = p_{00z} + p_{01z} + p_{10z} + p_{11z}
    $$
    Найдем маргинальные распределения $(X,Z)^T$ и $(Y,Z)^T$:
    $$
        P(X=x, Z=z) = \sum_{y=0}^{1} p_{xyz} = p_{x0z} + p_{x1z}
    $$
    $$
        P(Y=y, Z=z) = \sum_{x=0}^{1} p_{xyz} = p_{0yz} + p_{1yz}
    $$
    Тогда условие условной независимости перепишем в следующем виде:
    $$
        p_{xyz} (p_{00z} + p_{01z} + p_{10z} + p_{11z}) = (p_{x0z} + p_{x1z}) (p_{0yz} + p_{1yz})
    $$
    Это условие выполняется для всех $x=0,1$, $y=0,1$, $z=0,1$.
    Пусть $z$ фиксировано.
    Если $x=0$ и $y=0$, то:
    $$
        p_{00z} (p_{00z} + p_{01z} + p_{10z} + p_{11z}) = (p_{00z} + p_{01z}) (p_{00z} + p_{10z})
    $$
    $$
        p_{00z} p_{00z} + p_{00z} p_{01z} + p_{00z} p_{10z} + p_{00z} p_{11z} =
        p_{00z} p_{00z} + p_{00z} p_{10z} + p_{01z} p_{00z} + p_{01z} p_{10z}
    $$
    $$
        p_{00z} p_{11z} = p_{01z} p_{10z}
    $$
    Если $x=0$ и $y=1$, то:
    $$
        p_{01z} (p_{00z} + p_{01z} + p_{10z} + p_{11z}) = (p_{00z} + p_{01z}) (p_{01z} + p_{11z})
    $$
    $$
        p_{01z}p_{00z} + p_{01z}p_{01z} + p_{01z}p_{10z} + p_{01z}p_{11z} =
        p_{00z}p_{01z} + p_{00z} p_{11z} + p_{01z} p_{01z} + p_{01z} p_{11z}
    $$
    $$
        p_{01z}p_{10z}=p_{00z} p_{11z}
    $$
    Если $x=1$ и $y=0$, то:
    $$
        p_{10z} (p_{00z} + p_{01z} + p_{10z} + p_{11z}) = (p_{10z} + p_{11z}) (p_{00z} + p_{10z})
    $$
    $$
        p_{10z} p_{00z} + p_{10z} p_{01z} + p_{10z} p_{10z} + p_{10z} p_{11z} = p_{10z}p_{00z} + p_{10z}p_{10z} + p_{11z}p_{00z} + p_{11z}p_{10z}
    $$
    $$
        p_{10z} p_{01z} = p_{11z}p_{00z}
    $$
    Если $x=1$ и $y=1$, то:
    $$
        p_{11z} (p_{00z} + p_{01z} + p_{10z} + p_{11z}) = (p_{10z} + p_{11z}) (p_{01z} + p_{11z})
    $$
    $$
        p_{11z} p_{00z} + p_{11z} p_{01z} + p_{11z} p_{10z} + p_{11z} p_{11z} = p_{10z} p_{01z} + p_{10z}p_{11z} + p_{11z}p_{01z} +
        p_{11z} p_{11z}
    $$
    $$
        p_{11z} p_{00z} = p_{10z} p_{01z}
    $$
    Таким образом, из условной независимости $X$ и $Y$ при условии $Z$ следует
    $p_{00z}p_{11z}=p_{01z}p_{10z}$, где $z=0,1$.

    Доказательство в обратную сторону проводится аналогично.
\end{proof}

\begin{example}
    Пусть $(X,Y,Z)$ имеет трехмерное распределение Бернулли с вероятностями
    $p_{000}=0.15$, $p_{001}=0.1$, $p_{010}=0.3$, $p_{011}=0.1$, $p_{100}=0.05$, $p_{101}=0.1$,
    $p_{110}=0.1$, $p_{111}=0.1$.
    Заметим, что:
    $$p_{000}p_{110}=p_{010}p_{100}=0.015$$ $$p_{001}p_{111}=p_{011}p_{101}=0.01$$
    Значит из теоремы \ref{thm1} следует, что $X \ci Y \mid Z$.
\end{example}

\section{Частный коэффициент корреляции Пирсона}
Для удобства введем следующие обозначения: $$p_{x**}=P(X=x), \; p_{*y*}=P(Y=y), \; p_{**z}=P(Z=z)$$
$$p_{xy*}=P(X=x, Y=y), \; p_{x*z}=P(X=x, Z=z), \; p_{*yz}=P(Y=y, Z=z)$$
Символом $\Sigma$ будем обозначать ковариационную матрицу:
$$\Sigma =
    \begin{pmatrix}
        \sigma_{11} & \sigma_{12} & \sigma_{13} \\
        \sigma_{21} & \sigma_{22} & \sigma_{23} \\
        \sigma_{31} & \sigma_{32} & \sigma_{33}
    \end{pmatrix}
$$
Легко проверить, что $\sigma_{11}=D(X) = p_{1**}(1-p_{1**})$.

\begin{lemma}
    $$\sigma_{12}=\text{Cov}(X,Y)=p_{11*}-p_{1**}p_{*1*}$$
\end{lemma}

\begin{proof}
    Воспользуемся формулой $\text{Cov}(X,Y)=E(X Y)-$ $-E(X)E(Y)$.
    $$E(X Y) = 1 \cdot p_{11*} + 0 \cdot (p_{00*} + p_{01*} + p_{10*})=p_{11*}$$
    $$EX = 1 \cdot p_{1**} + 0 \cdot p_{0**}=p_{1**}$$
    $$ EY = 1 \cdot p_{*1*} + 0 \cdot p_{*0*} = p_{*1*}$$
    Таким образом, $\text{Cov}(X,Y)=p_{11*}-p_{1**}p_{*1*}$.
\end{proof}

Частный коэффициент корреляции Пирсона определяется через элементы обратной ковариационной матрицы $\Sigma^{-1}$:
$$
    \Sigma^{-1}=\begin{pmatrix}
        \sigma^{11} & \sigma^{12} & \sigma^{13} \\
        \sigma^{21} & \sigma^{22} & \sigma^{23} \\
        \sigma^{31} & \sigma^{32} & \sigma^{33}
    \end{pmatrix}
$$
Известно, что элемент $\sigma^{12}$ матрицы $\Sigma^{-1}$ выражается через соотношение
$\sigma^{12}=\dfrac{(-1)^{2+1}}{\text{det} (\Sigma)}M_{21}$, где
$
    M_{21}=\text{det}
    \begin{pmatrix}
        \sigma_{12} & \sigma_{13} \\
        \sigma_{32} & \sigma_{33}
    \end{pmatrix}
$.

\begin{lemma}\label{partial_cov}
    $$M_{21} = p_{**0}(p_{001}p_{111}-p_{011}p_{101}) + p_{**1} (p_{000}p_{110}-p_{010}p_{100})$$
\end{lemma}
\begin{proof}
    $$ M_{21}= \text{det}
        \begin{pmatrix}
            \sigma_{12} & \sigma_{13} \\
            \sigma_{23} & \sigma_{33}
        \end{pmatrix}
        = (p_{11*}-p_{1**}p_{*1*}) p_{**1}(1-p_{**1})-
    $$
    $$
        -(p_{1*1}-p_{1**}p_{**1})(p_{*11}-p_{*1*}p_{**1})=
    $$
    $$
        =p_{11*}p_{**1} - p_{11*}p_{**1}p_{**1} - p_{1**}p_{*1*}p_{**1} + p_{1**}p_{*1*}p_{**1}p_{**1}-
    $$
    $$
        -p_{1*1}p_{*11}+p_{1*1}p_{*1*}p_{**1}+p_{1**}p_{**1}p_{*11}-p_{1**}p_{**1}p_{*1*}p_{**1}=
    $$
    Заметим, что четвертое и восьмое слагаемые сокращаются. Распишем первое слагаемое как сумму вероятностей:
    $$
        =p_{111}p_{**1}+p_{110}p_{**1} - p_{11*}p_{**1}p_{**1} - p_{1**}p_{*1*}p_{**1} -
    $$
    $$
        -p_{1*1}p_{*11}+p_{1*1}p_{*1*}p_{**1}+p_{1**}p_{**1}p_{*11}=
    $$
    Осуществим перегруппировку слагаемых:
    $$
        =(p_{111}p_{**1}-p_{1*1}p_{*11})+p_{**1}(p_{110}-p_{11*}p_{**1} - p_{1**}p_{*1*} + p_{1*1}p_{*1*} + p_{1**}p_{*11})
    $$
    Преобразуем выражения для отдельных слагаемых.
    Заметим, что:
    $$
        p_{110}-p_{11*}p_{**1}=p_{110}-p_{110}p_{**1}-p_{111}p_{**1}=
    $$
    $$
        =p_{110}(1-p_{**1})-p_{111}p_{**1}=p_{110}p_{**0}-p_{111}p_{**1}
    $$
    Также заметим, что:
    $$
        -p_{1**}p_{*1*} + p_{1*1}p_{*1*} + p_{1**}p_{*11}=
    $$
    $$
        =-(p_{1*0}+p_{1*1})(p_{*10}+p_{*11})+p_{1*1}(p_{*10}+p_{*11}) + (p_{1*0}+p_{1*1})p_{*11}=
    $$
    $$
        =-p_{1*0}p_{*10}-p_{1*0}p_{*11}-p_{1*1}p_{*10}-p_{1*1}p_{*11}+
    $$
    $$
        +p_{1*1}p_{*10}+p_{1*1}p_{*11}+p_{1*0}p_{*11}+p_{1*1}p_{*11}=
    $$
    $$
        =-p_{1*0}p_{*10}+p_{1*1}p_{*11}
    $$
    Запишем выражение для $M_{21}$ с преобразованными слагаемыми:
    $$
        M_{21}=(p_{111}p_{**1}-p_{1*1}p_{*11})+p_{**1}((p_{110}p_{**0}-p_{1*0}p_{*10})-(p_{111}p_{**1}-p_{1*1}p_{*11}))=
    $$
    $$
        =(p_{111}p_{**1}-p_{1*1}p_{*11})+p_{**1}(p_{110}p_{**0}-p_{1*0}p_{*10})-p_{**1}(p_{111}p_{**1}-p_{1*1}p_{*11})=
    $$
    $$
        =(1-p_{**1})(p_{111}p_{**1}-p_{1*1}p_{*11})+p_{**1}(p_{110}p_{**0}-p_{1*0}p_{*10})=
    $$
    $$
        =p_{**0}(p_{111}p_{**1}-p_{1*1}p_{*11})+p_{**1}(p_{110}p_{**0}-p_{1*0}p_{*10})
    $$
    Снова преобразуем отдельные слагаемые.
    $$
        p_{111}p_{**1}-p_{1*1}p_{*11} = p_{111}(p_{001}+p_{011}+p_{101}+p_{111})-
        (p_{101}+p_{111})(p_{011}+p_{111})=
    $$
    $$
        = p_{111}p_{001}+p_{111}p_{011}+p_{111}p_{101}+p_{111}p_{111}
        - p_{101}p_{011}-p_{101}p_{111}-p_{111}p_{011}-p_{111}p_{111}=
    $$
    $$
        = p_{001}p_{111}-p_{011}p_{101}
    $$
    Аналогично преобразуем выражение:
    $$
        p_{110}p_{**0}-p_{1*0}p_{*10}=
        p_{110}(p_{000}+p_{010}+p_{100}+p_{110})-(p_{100}+p_{110})(p_{010}+p_{110})=
    $$
    $$
        =p_{110}p_{000}+p_{110}p_{010}+p_{110}p_{100}+p_{110}p_{110}
        -p_{100}p_{010}-p_{100}p_{110}-p_{110}p_{010}-p_{110}p_{110}=
    $$
    $$
        =p_{000}p_{110}-p_{010}p_{100}
    $$
    Таким образом:
    $$
        M_{21} = p_{**0}(p_{001}p_{111}-p_{011}p_{101}) + p_{**1} (p_{000}p_{110}-p_{010}p_{100})
    $$
\end{proof}
\begin{theorem}\label{1.2}
    Пусть $X$ и $Y$ условно независимы при условии $Z$. Тогда $\sigma^{12}=0$.
\end{theorem}
\begin{proof}
    Пусть $X$ и $Y$ условно независимы при условии $Z$. Тогда по теореме \ref{thm1}:
    $$p_{000}p_{110}=p_{010}p_{100}$$
    $$p_{001}p_{111}=p_{011}p_{101}$$
    Используя вышеприведенные соотношения, имеем:
    $$
        M_{21} = p_{**0}(p_{001}p_{111}-p_{011}p_{101}) + p_{**1} (p_{000}p_{110}-p_{010}p_{100})= 0
    $$
    Из $M_{21}=0$ непосредственно следует, что $\sigma^{12}=0$.
\end{proof}
В обратную сторону теорема \ref{1.2} неверна. Легко построить контрпример при $p_{**0}=0$. Далее покажем контрпример в невырожденном случае.
\begin{example}
    Пусть $p_{000}=0.15$, $p_{001}=0.1$, $p_{010}=0.1$, $p_{011}=0.15$, $p_{100}=0.1$, $p_{101}=0.15$, $p_{110}=0.15$, $p_{111}=0.1$.
    Тогда $p_{**0}=0.5$, $p_{**1}=0.5$ и
    $M_{21} = p_{**1}(p_{000}p_{110}-p_{010}p_{100}) + p_{**0}(p_{001}p_{111}-p_{011}p_{101})=$
    $= 0.5 \cdot (0.15 \cdot 0.15 - 0.1 \cdot 0.1) + 0.5 \cdot (0.1 \cdot 0.1 - 0.15 \cdot 0.15) = 0$.

    Однако, случайные величины $X$ и $Y$ условно зависимы при условии $Z$ поскольку:
    $$
        p_{000}p_{110}-p_{010}p_{100}=0.15 \cdot 0.15 - 0.1 \cdot 0.1 = 0.0125 \neq 0
    $$
    $$
        p_{001}p_{111}-p_{011}p_{101}=0.1 \cdot 0.1 - 0.15 \cdot 0.15 = -0.0125 \neq 0
    $$
\end{example}
\section{Трехмерное распределение Бернулли в экспоненциальном виде}
Пусть $(X,Y,Z)^T$ -- случайный вектор, имеющий трехмерное распределение Бернулли.
Данное распределение можно записать в экспоненциальном виде:
$$p(x,y,z)=P(X=x,Y=y,Z=z)=p_{000}^{(1-x)(1-y)(1-z)} \ldots p_{111}^{x y z}$$

\begin{lemma}\label{factorization}
    $$
        p(x,y,z)= \exp \Biggl\{ \ln p_{000} \Biggr\}
        \exp \Biggl\{  xyz \ln  \left(\dfrac{p_{001}p_{111}p_{010}p_{100}}{p_{011}p_{101}p_{000}p_{110}}\right) +$$
    $$ +
        x \ln\left(\dfrac{p_{100}}{p_{000}}\right) +  y \ln\left(\dfrac{p_{010}}{p_{000}}\right) +
        z \ln\left(\dfrac{p_{001}}{p_{000}}\right) +
    $$
    $$
        + xy \ln \left(\dfrac{p_{000}p_{110}}{p_{010}p_{100}}\right) +
        xz \ln \left(\dfrac{p_{000}p_{101}}{p_{001}p_{100}}\right) +
        yz \ln \left(\dfrac{p_{000}p_{011}}{p_{001}p_{010}}\right) \Biggr\}
    $$
\end{lemma}

\begin{proof}
    $$
        p(x,y,z) = p_{000}^{(1-x)(1-y)(1-z)} \ldots p_{111}^{x y z} =
    $$
    $$
        =\exp \Biggl\{ (1-x)(1-y)(1-z) \ln p_{000} +
        (1-x)(1-y)z \ln p_{001}+
    $$
    $$
        + (1-x)y(1-z) \ln p_{010} + (1-x)y z \ln p_{011} +  x(1-y)(1-z) \ln p_{100} +
    $$
    $$
        +   x(1-y) z \ln p_{101}
        +   x y (1-z) \ln p_{110} +   x y z \ln p_{111} \Biggr\} =
    $$
    $$
        =\exp \Biggl\{   ( 1 - y -  x +  x y
        -  z +  y z +  x z -  x y z ) \ln p_{000} +
    $$
    $$
        +    (z -  y z -  x z +  x y z) \ln p_{001}  +
          (y -  y z -  x y +  x y z)  \ln p_{010} +
    $$
    $$
        +    (y z -  x y z ) \ln p_{011} +
           (x -  x z -  x y +  x y z ) \ln p_{100} +
    $$
    $$
        +   (x z -  x y z ) \ln p_{101} +   (x y -  x y z) \ln p_{110} +
          x y z \ln p_{111} \Biggr\}=
    $$
    $$
        = \exp \Biggl\{ \ln p_{000} \Biggr\}
        \exp \Biggl\{  xyz \ln  \left(\dfrac{p_{001}p_{111}p_{010}p_{100}}{p_{011}p_{101}p_{000}p_{110}}\right) +$$
    $$ +
        x \ln\left(\dfrac{p_{100}}{p_{000}}\right) +  y \ln\left(\dfrac{p_{010}}{p_{000}}\right) +
        z \ln\left(\dfrac{p_{001}}{p_{000}}\right) +
    $$
    $$
        + xy \ln \left(\dfrac{p_{000}p_{110}}{p_{010}p_{100}}\right) +
        xz \ln \left(\dfrac{p_{000}p_{101}}{p_{001}p_{100}}\right) +
        yz \ln \left(\dfrac{p_{000}p_{011}}{p_{001}p_{010}}\right) \Biggr\}
    $$
\end{proof}

\section{Равномерно наиболее мощный тест}
Пусть
$$
    \begin{pmatrix}
        x_1 \\
        y_1 \\
        z_1
    \end{pmatrix},
    \begin{pmatrix}
        y_2 \\
        y_2 \\
        z_2
    \end{pmatrix}, \ldots,
    \begin{pmatrix}
        x_n \\
        y_n \\
        z_n
    \end{pmatrix}
$$ -- повторная выборка из распределения случайного вектора $(X,Y,Z)^T$.
Из леммы \ref{factorization} непосредственно следует, что плотность совместного распределения повторной выборки имеет вид
$$p(x,y,z) = \prod_{i=1}^n p(x_i,y_i,z_i) =$$
$$
        = \exp \Biggl\{ n \ln p_{000}\Biggr\}
        \exp \Biggl\{ \ln  \left(\dfrac{p_{001}p_{111}p_{010}p_{100}}{p_{011}p_{101}p_{000}p_{110}}\right) \sum_{i=1}^n x_i y_i z_i +$$
    $$ +
        \ln\left(\dfrac{p_{100}}{p_{000}}\right) \sum_{i=1}^{n} x_i + \ln\left(\dfrac{p_{010}}{p_{000}}\right) \sum_{i=1}^{n} y_i +
        \ln\left(\dfrac{p_{001}}{p_{000}}\right) \sum_{i=1}^{n} z_i +
    $$
    $$
        +\ln \left(\dfrac{p_{000}p_{110}}{p_{010}p_{100}}\right) \sum_{i=1}^n x_i y_i +
        \ln \left(\dfrac{p_{000}p_{101}}{p_{001}p_{100}}\right) \sum_{i=1}^n x_i z_i +
        \ln \left(\dfrac{p_{000}p_{011}}{p_{001}p_{010}}\right) \sum_{i=1}^n y_i z_i \Biggr\}
    $$

Пусть $\theta = \ln  \left(\dfrac{p_{001}p_{111}p_{010}p_{100}}{p_{011}p_{101}p_{000}p_{110}}\right)$.
Можно проверить, что если выполнено одно из условий:
\begin{itemize}
    \item $X \ci Y \mid Z$
    \item $X \ci Z \mid Y$
    \item $Y \ci Z \mid X$
\end{itemize}
то параметр $\theta$ примет значение $\theta_0=0$ (а в обратную сторону?). В тесте структуры Неймана для проверки гипотезы для проверки гипотезы
$H: \theta = \theta_0$ против альтернативы $K: \theta \neq \theta_0$ используются следующие статистики:
$$
    U = \sum_{i=1}^n x_i y_i z_i,
    T_1 = \sum_{i=1}^n x_i y_i,
    T_2 = \sum_{i=1}^n x_i z_i,
    T_3 = \sum_{i=1}^n y_i z_i
$$
$$
    T_4 = \sum_{i=1}^n x_i,
    T_5 = \sum_{i=1}^n y_i,
    T_6 = \sum_{i=1}^n z_i
$$
Для построения теста необходимо найти распределение:
$$
    P(U=u \mid T_1=t_1, T_2=t_2, T_3=t_3, T_4=t_4, T_5=t_5, T_6=t_6)
$$
Найдем совместное распределение вектора $(U,T_1,T_2,T_3,T_4,T_5,T_6)$.
\begin{lemma}
    $$P(U=u, T_1=t_1, T_2=t_2, T_3=t_3, T_4=t_4, T_5=t_5, T_6=t_6)=$$
    $$=\frac{n!}{\prod_{i=1}^8 k_i(u)!} \left(\dfrac{p_{001}p_{010}p_{100}p_{111}}{p_{000}p_{011}p_{101}p_{110}}\right)^u
        \left(\dfrac{p_{000} p_{110}}{p_{010} p_{100}}\right)^{t_1}\left(\dfrac{p_{000}p_{101}}{p_{001}p_{100}}\right)^{t_2}
        \left(\dfrac{p_{000}p_{011}}{p_{001}p_{010}}\right)^{t_3} \cdot$$
    $$
        \cdot\left(\dfrac{p_{100}}{p_{000}}\right)^{t_4}
        \left(\dfrac{p_{010}}{p_{000}}\right)^{t_5} \left(\dfrac{p_{001}}{p_{000}}\right)^{t_6} p_{000}^n
    $$
    где
    $k_1(u)=u$, $k_2(u)=t_1-u$, $k_3(u)=t_2-u$, $k_4(u)=t_3-u$, $k_5(u)=t_4-t_1-t_2+u$, $k_6(u)=t_5-t_1-t_3+u$,
    $k_7(u)=t_6 - t_2 - t_3 + u$, $k_8(u)=n-u+t_1+t_2+t_3-t_4-t_5-t_6$
\end{lemma}
\begin{proof}
    $$
        P(U=u, T_1=t_1, T_2=t_2, T_3=t_3, T_4=t_4, T_5=t_5, T_6=t_6)=
    $$
    $$
        =P\biggl(\sum_{i=1}^n x_i y_i z_i=u, \sum_{i=1}^n x_i y_i=t_1, \sum_{i=1}^n x_i z_i=t_2,\sum_{i=1}^n y_i z_i=t_3,
        $$
        $$
        \sum_{i=1}^n x_i=t_4,\sum_{i=1}^n y_i=t_5, \sum_{i=1}^n z_i=t_6\biggr)=
    $$
    $$
        =P\biggl(\sum_{i=1}^n x_i y_i z_i=u, \sum_{i=1}^n x_i y_i (1- z_i)=t_1-u, \sum_{i=1}^n x_i (1-y_i) z_i=t_2-u,
    $$
    $$
        \sum_{i=1}^n (1-x_i) y_i z_i=t_3-u,
        \sum_{i=1}^{n} x_i(1-y_i)(1-z_i)=t_4-t_1-t_2+u,
    $$
    $$
        \sum_{i=1}^{n} (1-x_i)y_i(1-z_i)=t_5-t_1-t_3+u,
        \sum_{i=1}^{n} (1-x_i)(1-y_i)z_i = t_6 - t_2 - t_3 + u,
    $$
    $$
        \sum_{i=1}^n (1-x_i)(1-y_i)(1-z_i)=n-u+t_1+t_2+t_3-t_4-t_5-t_6\biggr)=
    $$
    $$
        = \frac{n!}{\prod_{i=1}^8 k_i(u)!} p_{111}^u p_{110}^{t_1-u} p_{101}^{t_2-u} p_{011}^{t_3-u}
        p_{100}^{t_4-t_1-t_2+u} p_{010}^{t_5-t_1-t_3+u} p_{001}^{t_6 - t_2 - t_3 + u} \cdot
    $$
    $$
        \cdot p_{000}^{n-u+t_1+t_2+t_3-t_4-t_5-t_6}
        =
    $$
    $$=\frac{n!}{\prod_{i=1}^8 k_i(u)!} \left(\dfrac{p_{001}p_{010}p_{100}p_{111}}{p_{000}p_{011}p_{101}p_{110}}\right)^u
        \left(\dfrac{p_{000} p_{110}}{p_{010} p_{100}}\right)^{t_1}\left(\dfrac{p_{000}p_{101}}{p_{001}p_{100}}\right)^{t_2}
        \left(\dfrac{p_{000}p_{011}}{p_{001}p_{010}}\right)^{t_3} \cdot$$
    $$
        \cdot\left(\dfrac{p_{100}}{p_{000}}\right)^{t_4}
        \left(\dfrac{p_{010}}{p_{000}}\right)^{t_5} \left(\dfrac{p_{001}}{p_{000}}\right)^{t_6} p_{000}^n
    $$
\end{proof}

\begin{lemma}
    $$P_{\theta_0}(U=u \mid T_1=t_1, T_2=t_2, T_3=t_3, T_4=t_4, T_5=t_5, T_6=t_6)=\dfrac{\frac{1}{\prod_{i=1}^8 k_i(u)!}}
        {\sum_{s} \frac{1}{\prod_{i=1}^8 k_i(s)!}}$$
\end{lemma}
\begin{proof}
    $$P(T_1=t_1, T_2=t_2, T_3=t_3, T_4=t_4, T_5=t_5, T_6=t_6)=$$
    $$=\sum_{s} P(U=s, T_1=t_1, T_2=t_2, T_3=t_3, T_4=t_4, T_5=t_5, T_6=t_6)$$
    $$P(U=u \mid T_1=t_1, T_2=t_2, T_3=t_3, T_4=t_4, T_5=t_5, T_6=t_6)=$$
    $$=\dfrac{\frac{n!}{\prod_{i=1}^8 k_i(u)!} \left(\dfrac{p_{001}p_{010}p_{100}p_{111}}{p_{000}p_{011}p_{101}p_{110}}\right)^u}
        {\sum_{s} \frac{n!}{\prod_{i=1}^8 k_i(s)!} \left(\dfrac{p_{001}p_{010}p_{100}p_{111}}{p_{000}p_{011}p_{101}p_{110}}\right)^s}$$
    При истинности гипотезы $\theta=\theta_0=0$ параметр $\dfrac{p_{001}p_{010}p_{100}p_{111}}{p_{000}p_{011}p_{101}p_{110}}=1$.
    $$P_{\theta_0}(U=u \mid T_1=t_1, T_2=t_2, T_3=t_3, T_4=t_4, T_5=t_5, T_6=t_6)=\dfrac{\frac{1}{\prod_{i=1}^8 k_i(u)!}}
        {\sum_{s} \frac{1}{\prod_{i=1}^8 k_i(s)!}}$$
\end{proof}

Приведем способ, с помощью которого на компьютере можно эффективно вычислить значение $\dfrac{\frac{1}{\prod_{i=1}^8 k_i(u)!}}
{\sum_{s} \frac{1}{\prod_{i=1}^8 k_i(s)!}}$. Пусть $f(i)=\sum_{j=1}^{i} \ln(j)$. Проведем некоторые преобразования искомого выражения:
$$
\dfrac{\frac{1}{\prod_{i=1}^8 k_i(u)!}}{\sum_{s} \frac{1}{\prod_{i=1}^8 k_i(s)!}}=
\dfrac{\exp \biggl\{ \ln \biggl( \frac{1}{\prod_{i=1}^8 k_i(u)!} \biggr) \biggr\}}
{\sum_{s} \exp \biggl\{ \ln \biggl( \frac{1}{\prod_{i=1}^8 k_i(s)!} \biggr) \biggr\}}
= \dfrac{\exp \biggl\{ -\sum_{i=1}^8 \ln(k_i(u)!) \biggr\}}{\sum_{s} \exp \biggl\{ -\sum_{i=1}^8 \ln(k_i(s)!) \biggr\}} =
$$
$$
= \dfrac{\exp \biggl\{ -\sum_{i=1}^8 f(k_i(u)) \biggr\}}{\sum_{s} \exp \biggl\{ -\sum_{i=1}^8 f(k_i(s)) \biggr\}}
$$
Полученное выражение можно посчитать с помощью функции
$$
\text{softmax}(x,i)=\dfrac{\exp\{x_i\}}{\sum_{j=1}^{n} \exp\{x_j\}}, x=(x_1,\ldots,x_n) \in \mathbb{R}^n
$$
Благодаря свойству
$$
\text{softmax}(x,i)=\dfrac{\exp\{x_i\}}{\sum_{j=1}^{n} \exp\{x_j\}} = \dfrac{\exp\{x_i - C\}}{\sum_{j=1}^{n} \exp\{x_j - C\}}
$$
современные компьютеры умеют вычислять $\text{softmax}$ даже при больших значениях $x_i$.
Для вычисления $\text{softmax}$ в вышеприведенной формуле полагают $C=\max_{1\leq j \leq n} x_j$.
\end{document}
