\documentclass{article}
\usepackage{graphicx}

\usepackage{geometry}
\geometry{left=2cm, right=2cm, top=2cm, bottom=2cm}

\usepackage[russian]{babel}

\usepackage{amsmath,amssymb,amsfonts}
\usepackage{amsthm}
\usepackage{hyperref}

\theoremstyle{definition}
\newtheorem{definition}{Определение}[section]
\newtheorem{theorem}{Теорема}[section]
\newtheorem{example}{Пример}[section]
\newtheorem{lemma}{Лемма}[section]

\def\ci{\perp\!\!\!\perp}
\usepackage{xcolor}

\begin{document}

\section{Введение}

Пусть $\{0,1\}^n = \{(x_1,\ldots,x_n): x_i \in \{0,1\} \}$.

\begin{definition}
    Случайный вектор $X=(X_1, X_2, X_3)^T$ имеет трехмерное распределение Бернулли,
    если множество его возможных значений $\{0,1\}^3$ и заданы вероятности:
    $$P(X_1=i,X_2=j,X_3=k)=p_{ijk} \geq 0, \quad \sum_{i=0}^{1}\sum_{j=0}^{1}\sum_{k=0}^{1}p_{ijk}=1$$
\end{definition}

\begin{definition}
    Пусть $X=(X_1,X_2,X_3)^T$ -- дискретный случайный вектор.
    Говорят, что случайные величины $X_1$ и $X_2$ условно независимы при условии $X_3$,
    и пишут $X_1 \ci X_2 \mid X_3$, если
    для любых $i,j$ и $k$, такого что $P(X_3=k)>0$, выполнено:
    $$
        P(X_1=i, X_2=j \mid X_3 = k) = P(X_1=i \mid X_3 = k) P(X_2=j \mid X_3 = k)
    $$
\end{definition}

\begin{theorem}\label{thm1}
    Пусть $(X_1,X_2,X_3)^T$ -- случайный вектор, имеющий трехмерное распределение Бернулли, и $P(X_3=0)>0$.
    Случайные величины $X_1$ и $X_2$ условно независимы при условии $X_3$ тогда и только тогда, когда
    $p_{00k}p_{11k}=p_{01k}p_{10k}$, где $k \in \{0,1\}$.
\end{theorem}

\begin{proof}
    Пусть $X_1 \ci X_2 \mid X_3$. Значит, для любых $(i,j,k) \in \{0,1\}^3$ выполнено условие:
    \begin{equation}\label{cond_ind}
        P(X_1=i, X_2=j \mid X_3 = k) = P(X_1=i \mid X_3 = k) P(X_2=j \mid X_3 = k)
    \end{equation}
    Найдем маргинальное распределение случайной величины $X_3$:
    $$
        P(X_3=k)=\sum_{i=0}^{1} \sum_{j=0}^{1} p_{ijk} = p_{00k} + p_{01k} + p_{10k} + p_{11k}
    $$
    Найдем маргинальные распределения $(X_1,X_3)^T$ и $(X_2,X_3)^T$:
    $$
        P(X_1=i, X_3=k) = \sum_{j=0}^{1} p_{ijk} = p_{i0k} + p_{i1k}
    $$
    $$
        P(X_2=j, X_3=k) = \sum_{i=0}^{1} p_{ijk} = p_{0jk} + p_{1jk}
    $$
    Запишем условные вероятности из условия \ref{cond_ind}:
    $$
        P(X_1=i, X_2=j \mid X_3 =k) = \dfrac{P(X_1=i, X_2=j , X_3 =k)}{P(X_3=k)} = \dfrac{p_{ijk}}{p_{00k} + p_{01k} + p_{10k} + p_{11k}}
    $$
    $$
        P(X_1=i \mid X_3 = k) = \dfrac{P(X_1=i, X_3 = k)}{P(X_3=k)} = \dfrac{p_{i0k} + p_{i1k}}{p_{00k} + p_{01k} + p_{10k} + p_{11k}}
    $$
    $$
        P(X_2=j \mid X_3 = k) = \dfrac{P(X_2=j, X_3=k)}{P(X_3=k)}=\dfrac{p_{0jk} + p_{1jk}}{p_{00k} + p_{01k} + p_{10k} + p_{11k}}
    $$
    Тогда условие \ref{cond_ind} можно переписать в следующем виде:
    $$
        \dfrac{p_{ijk}}{p_{00k} + p_{01k} + p_{10k} + p_{11k}} = \dfrac{p_{i0k} + p_{i1k}}{p_{00k} + p_{01k} + p_{10k} + p_{11k}}
        \dfrac{p_{0jk} + p_{1jk}}{p_{00k} + p_{01k} + p_{10k} + p_{11k}}
    $$
    $$
        p_{ijk} (p_{00k} + p_{01k} + p_{10k} + p_{11k}) = (p_{i0k} + p_{i1k}) (p_{0jk} + p_{1jk})
    $$
    Это условие выполняется для всех $(i,j,k) \in \{0,1\}^3$.
    Пусть $k \in \{0,1\}$ фиксировано.
    Если $i=0$ и $j=0$, то:
    $$
        p_{00k} (p_{00k} + p_{01k} + p_{10k} + p_{11k}) = (p_{00k} + p_{01k}) (p_{00k} + p_{10k})
    $$
    $$
        p_{00k} p_{00k} + p_{00k} p_{01k} + p_{00k} p_{10k} + p_{00k} p_{11k} =
        p_{00k} p_{00k} + p_{00k} p_{10k} + p_{01k} p_{00k} + p_{01k} p_{10k}
    $$
    $$
        p_{00k} p_{11k} = p_{01k} p_{10k}
    $$
    Если $i=0$ и $j=1$, то:
    $$
        p_{01k} (p_{00k} + p_{01k} + p_{10k} + p_{11k}) = (p_{00k} + p_{01k}) (p_{01k} + p_{11k})
    $$
    $$
        p_{01k}p_{00k} + p_{01k}p_{01k} + p_{01k}p_{10k} + p_{01k}p_{11k} =
        p_{00k}p_{01k} + p_{00k} p_{11k} + p_{01k} p_{01k} + p_{01k} p_{11k}
    $$
    $$
        p_{01k}p_{10k}=p_{00k} p_{11k}
    $$
    Если $i=1$ и $j=0$, то:
    $$
        p_{10k} (p_{00k} + p_{01k} + p_{10k} + p_{11k}) = (p_{10k} + p_{11k}) (p_{00k} + p_{10k})
    $$
    $$
        p_{10k} p_{00k} + p_{10k} p_{01k} + p_{10k} p_{10k} + p_{10k} p_{11k} = p_{10k}p_{00k} + p_{10k}p_{10k} + p_{11k}p_{00k} + p_{11k}p_{10k}
    $$
    $$
        p_{10k} p_{01k} = p_{11k}p_{00k}
    $$
    Если $i=1$ и $j=1$, то:
    $$
        p_{11k} (p_{00k} + p_{01k} + p_{10k} + p_{11k}) = (p_{10k} + p_{11k}) (p_{01k} + p_{11k})
    $$
    $$
        p_{11k} p_{00k} + p_{11k} p_{01k} + p_{11k} p_{10k} + p_{11k} p_{11k} = p_{10k} p_{01k} + p_{10k}p_{11k} + p_{11k}p_{01k} +
        p_{11k} p_{11k}
    $$
    $$
        p_{11k} p_{00k} = p_{10k} p_{01k}
    $$
    Таким образом, при $(i,j)\in \{0,1\}^2$ и фиксированном $k\in \{0,1\}$ из условия \ref{cond_ind} следует:
    $$p_{00k}p_{11k}=p_{01k}p_{10k}$$

    Поскольку в вышеприведенных рассуждениях все операции обратимые, то доказательство в обратную сторону проводится аналогично.
\end{proof}

\begin{example}
    Пусть $(X_1,X_2,X_3)$ имеет трехмерное распределение Бернулли с вероятностями
    $p_{000}=0.15$, $p_{001}=0.1$, $p_{010}=0.3$, $p_{011}=0.1$, $p_{100}=0.05$, $p_{101}=0.1$,
    $p_{110}=0.1$, $p_{111}=0.1$.
    Заметим, что:
    $$p_{000}p_{110}=p_{010}p_{100}=0.015$$ $$p_{001}p_{111}=p_{011}p_{101}=0.01$$
    Значит из теоремы \ref{thm1} следует, что $X_1 \ci X_2 \mid X_3$.
\end{example}

\section{Частный коэффициент корреляции Пирсона}
Для удобства введем следующие обозначения: $$p_{i**}=P(X_1=i), \quad p_{*j*}=P(X_2=j), \quad p_{**k}=P(X_3=k)$$
$$p_{ij*}=P(X_1=i, X_2=j), \quad p_{i*k}=P(X_1=i, X_3=k), \quad p_{*jk}=P(X_2=j, X_3=k)$$
Далее символом $\Sigma$ будем обозначать ковариационную матрицу:
$$\Sigma =
    \begin{pmatrix}
        \sigma_{11} & \sigma_{12} & \sigma_{13} \\
        \sigma_{21} & \sigma_{22} & \sigma_{23} \\
        \sigma_{31} & \sigma_{32} & \sigma_{33}
    \end{pmatrix}
$$
Легко проверить, что $\sigma_{11}=D(X_1) = p_{1**}(1-p_{1**})$.

\begin{lemma}
    $$\sigma_{12}=\text{Cov}(X_1,X_2)=p_{11*}-p_{1**}p_{*1*}$$
\end{lemma}

\begin{proof}
    Воспользуемся формулой $\text{Cov}(X_1,X_2)=E(X_1 X_2)-E(X_1)E(X_2)$.
    $$E(X_1 X_2) = 1 \cdot p_{11*} + 0 \cdot (p_{00*} + p_{01*} + p_{10*})=p_{11*}$$
    $$EX_1 = 1 \cdot p_{1**} + 0 \cdot p_{0**}=p_{1**}$$
    $$ EX_2 = 1 \cdot p_{*1*} + 0 \cdot p_{*0*} = p_{*1*}$$
    Таким образом, $\text{Cov}(X_1,X_2)=p_{11*}-p_{1**}p_{*1*}$.
\end{proof}

% Сформулируем следующую теорему.
% \begin{theorem}
%     Случайные величины $X_1$ и $X_2$ независимы тогда и только тогда, когда $\sigma_{12}=0$.
% \end{theorem}
% \begin{proof}
%     Пусть случайные величины $X_1$ и $X_2$ независимы. Тогда выполнено условие:
%     $$
%     P(X_1=1,X_2=1)=P(X_1=1)P(X_2=1)
%     $$
%     Перепишем его в новых обозначениях и преобразуем:
%     $$
%     p_{11*}-p_{1**}p_{*1*}=0
%     $$
%     Из чего следует, что $\sigma_{12}=0$.

%     Пусть $\sigma_{12}=0$, то есть $p_{11*}-p_{1**}p_{*1*}=0$. Другими словами: $$P(X_1=1, X_2=1)=P(X_1=1)P(X_2=1)$$
%     Из чего следует, что $X_1$ и $X_2$ независимы (поскольку независимость событий $A$ и $B$ эквивалетна независимости событий
%     $\overline{A}$ и $B$, $A$ и $\overline{B}$, $\overline{A}$ и $\overline{B}$).
% \end{proof}

Частный коэффициент корреляции Пирсона определяется через элементы обратной ковариационной матрицы $\Sigma^{-1}$:
$$
    \Sigma^{-1}=\begin{pmatrix}
        \sigma^{11} & \sigma^{12} & \sigma^{13} \\
        \sigma^{21} & \sigma^{22} & \sigma^{23} \\
        \sigma^{31} & \sigma^{32} & \sigma^{33}
    \end{pmatrix}
$$
Из линейной алгебры известно, что элемент $\sigma^{12}$ матрицы $\Sigma^{-1}$ выражается через соотношение
$\sigma^{12}=\dfrac{(-1)^{2+1}}{\text{det} (\Sigma)}M_{21}$, где
$$
    M_{21}=\text{det}
    \begin{pmatrix}
        \sigma_{12} & \sigma_{13} \\
        \sigma_{32} & \sigma_{33}
    \end{pmatrix}
$$

\begin{lemma}\label{partial_cov}
    $$M_{21} = p_{**0}(p_{001}p_{111}-p_{011}p_{101}) + p_{**1} (p_{000}p_{110}-p_{010}p_{100})$$
\end{lemma}
\begin{proof}
    $$ M_{21}= \text{det}
        \begin{pmatrix}
            \sigma_{12} & \sigma_{13} \\
            \sigma_{23} & \sigma_{33}
        \end{pmatrix}
        = (p_{11*}-p_{1**}p_{*1*}) p_{**1}(1-p_{**1})-(p_{1*1}-p_{1**}p_{**1})(p_{*11}-p_{*1*}p_{**1})=
    $$
    Раскроем скобки:
    $$
        =p_{11*}p_{**1} - p_{11*}p_{**1}p_{**1} - p_{1**}p_{*1*}p_{**1} + p_{1**}p_{*1*}p_{**1}p_{**1}-
    $$
    $$
        -p_{1*1}p_{*11}+p_{1*1}p_{*1*}p_{**1}+p_{1**}p_{**1}p_{*11}-p_{1**}p_{**1}p_{*1*}p_{**1}=
    $$
    Сократим 4-е и 8-е слагаемые. Распишем 1-е слагаемое как сумму вероятностей:
    $$
        =(p_{111}p_{**1}+p_{110}p_{**1}) - p_{11*}p_{**1}p_{**1} - p_{1**}p_{*1*}p_{**1} -p_{1*1}p_{*11}+p_{1*1}p_{*1*}p_{**1}+p_{1**}p_{**1}p_{*11}=
    $$
    Перегруппируем слагаемые.
    $$
        =(p_{111}p_{**1}-p_{1*1}p_{*11})+p_{**1}(p_{110}-p_{11*}p_{**1} - p_{1**}p_{*1*} + p_{1*1}p_{*1*} + p_{1**}p_{*11})
    $$
    Заметим, что:
    $$
        p_{110}-p_{11*}p_{**1}=p_{110}-p_{110}p_{**1}-p_{111}p_{**1}=p_{110}(1-p_{**1})-p_{111}p_{**1}=p_{110}p_{**0}-p_{111}p_{**1}
    $$
    Также заметим, что:
    $$
        -p_{1**}p_{*1*} + p_{1*1}p_{*1*} + p_{1**}p_{*11}=
    $$
    $$
        =-(p_{1*0}+p_{1*1})(p_{*10}+p_{*11})+p_{1*1}(p_{*10}+p_{*11}) + (p_{1*0}+p_{1*1})p_{*11}=
    $$
    $$
        =-p_{1*0}p_{*10}-p_{1*0}p_{*11}-p_{1*1}p_{*10}-p_{1*1}p_{*11}+p_{1*1}p_{*10}+p_{1*1}p_{*11}+p_{1*0}p_{*11}+p_{1*1}p_{*11}=
    $$
    $$
        =-p_{1*0}p_{*10}+p_{1*1}p_{*11}
    $$
    Запишем выражение для $M_{21}$:
    $$
        M_{21}=(p_{111}p_{**1}-p_{1*1}p_{*11})+p_{**1}((p_{110}p_{**0}-p_{1*0}p_{*10})-(p_{111}p_{**1}-p_{1*1}p_{*11}))=
    $$
    $$
        =(p_{111}p_{**1}-p_{1*1}p_{*11})+p_{**1}(p_{110}p_{**0}-p_{1*0}p_{*10})-p_{**1}(p_{111}p_{**1}-p_{1*1}p_{*11})=
    $$
    $$
        =(1-p_{**1})(p_{111}p_{**1}-p_{1*1}p_{*11})+p_{**1}(p_{110}p_{**0}-p_{1*0}p_{*10})=
    $$
    $$
        =p_{**0}(p_{111}p_{**1}-p_{1*1}p_{*11})+p_{**1}(p_{110}p_{**0}-p_{1*0}p_{*10})
    $$
    Преобразуем выражение:
    $$
        p_{111}p_{**1}-p_{1*1}p_{*11} = p_{111}(p_{001}+p_{011}+p_{101}+p_{111})-
        (p_{101}+p_{111})(p_{011}+p_{111})=
    $$
    $$
        = p_{111}p_{001}+p_{111}p_{011}+p_{111}p_{101}+p_{111}p_{111}
        - p_{101}p_{011}-p_{101}p_{111}-p_{111}p_{011}-p_{111}p_{111}=
    $$
    $$
        = p_{001}p_{111}-p_{011}p_{101}
    $$
    Аналогично преобразуем выражение:
    $$
        p_{110}p_{**0}-p_{1*0}p_{*10}=
        p_{110}(p_{000}+p_{010}+p_{100}+p_{110})-(p_{100}+p_{110})(p_{010}+p_{110})=
    $$
    $$
        =p_{110}p_{000}+p_{110}p_{010}+p_{110}p_{100}+p_{110}p_{110}
        -p_{100}p_{010}-p_{100}p_{110}-p_{110}p_{010}-p_{110}p_{110}=
    $$
    $$
        =p_{000}p_{110}-p_{010}p_{100}
    $$
    Таким образом:
    $$
        M_{21} = p_{**0}(p_{001}p_{111}-p_{011}p_{101}) + p_{**1} (p_{000}p_{110}-p_{010}p_{100})
    $$
\end{proof}
\begin{theorem}\label{1.2}
    Пусть $X_1$ и $X_2$ условно независимы при условии $X_3$. Тогда $\sigma^{12}=0$.
\end{theorem}
\begin{proof}
    Пусть $X_1$ и $X_2$ условно независимы при условии $X_3$. Тогда по теореме \ref{thm1}:
    $$p_{000}p_{110}=p_{010}p_{100}$$
    $$p_{001}p_{111}=p_{011}p_{101}$$
    Используя вышеприведенные соотношения, имеем:
    $$
        M_{21} = p_{**0}(p_{001}p_{111}-p_{011}p_{101}) + p_{**1} (p_{000}p_{110}-p_{010}p_{100})=p_{**0}\cdot 0 + p_{**1} \cdot 0 = 0
    $$
    Из $M_{21}=0$ непосредственно следует, что $\sigma^{12}=0$.
\end{proof}
В обратную сторону теорема \ref{1.2} неверна. Легко построить контрпример при $p_{**0}=0$. Мы же покажем контрпример в невырожденном случае.
\begin{example}
    Пусть $p_{000}=0.15$, $p_{001}=0.1$, $p_{010}=0.1$, $p_{011}=0.15$, $p_{100}=0.1$, $p_{101}=0.15$, $p_{110}=0.15$, $p_{111}=0.1$.
    Тогда $p_{**0}=0.5$, $p_{**1}=0.5$ и

    $$M_{21} = p_{**1}(p_{000}p_{110}-p_{010}p_{100}) + p_{**0}(p_{001}p_{111}-p_{011}p_{101})=$$
    $$= 0.5 \cdot (0.15 \cdot 0.15 - 0.1 \cdot 0.1) + 0.5 \cdot (0.1 \cdot 0.1 - 0.15 \cdot 0.15) = 0$$

    Однако, случайные величины $X_1$ и $X_2$ условно зависимы при условии $X_3$ поскольку:
    $$
        p_{000}p_{110}-p_{010}p_{100}=0.15 \cdot 0.15 - 0.1 \cdot 0.1 = 0.0125 \neq 0
    $$
    $$
        p_{001}p_{111}-p_{011}p_{101}=0.1 \cdot 0.1 - 0.15 \cdot 0.15 = -0.0125 \neq 0
    $$
\end{example}
\section{Равномерно наиболее мощный тест}
Пусть $(X,Y,Z)^T$ -- случайный вектор, имеющий трехмерное распределение Бернулли.
Запишем данное распределение в экспоненциальном виде:
$$p(x_i,y_i,z_i)=P(X=x_i,Y=y_i,Z=z_i)=p_{000}^{(1-x_i)(1-y_i)(1-z_i)} p_{001}^{(1-x_i)(1-y_i)z_i}\ldots p_{111}^{x_i y_i z_i}=$$
$$=\exp\{(1-x_i)(1-y_i)(1-z_i) \ln p_{000} + (1-x_i)(1-y_i)z_i \ln p_{001} + \ldots + x_i y_i z_i \ln p_{111}\}$$

Пусть
$
    \begin{pmatrix}
        x_1 \\
        y_1 \\
        z_1
    \end{pmatrix},
    \begin{pmatrix}
        x_2 \\
        y_2 \\
        z_2
    \end{pmatrix}, \ldots,
    \begin{pmatrix}
        x_n \\
        y_n \\
        z_n
    \end{pmatrix}
$ -- повторная выборка из распределения случайного вектора $\begin{pmatrix}
        X \\
        Y \\
        Z
    \end{pmatrix}$.
Плотность совместного распределения повторной выборки имеет вид
$p(x,y,z) = \prod_{i=1}^n p(x_i,y_i,z_i)$.
\begin{lemma}
    $$
        p(x,y,z)= \exp \Biggl\{ n \ln p_{000}\Biggl\}
        \exp \Biggl\{ \ln  \left(\dfrac{p_{001}p_{111}}{p_{011}p_{101}}  \dfrac{p_{010}p_{100}}{p_{000}p_{110}}\right) \sum_{i=1}^n x_i y_i z_i +
        \ln\left(\dfrac{p_{100}}{p_{000}}\right) \sum_{i=1}^{n} x_i + \ln\left(\dfrac{p_{010}}{p_{000}}\right) \sum_{i=1}^{n} y_i +
    $$
    $$
        + \ln\left(\dfrac{p_{001}}{p_{000}}\right) \sum_{i=1}^{n} z_i +\ln \left(\dfrac{p_{000}p_{110}}{p_{010}p_{100}}\right) \sum_{i=1}^n x_i y_i +
        \ln \left(\dfrac{p_{000}p_{101}}{p_{001}p_{100}}\right) \sum_{i=1}^n x_i z_i +
        \ln \left(\dfrac{p_{000}p_{011}}{p_{001}p_{010}}\right) \sum_{i=1}^n y_i z_i \Biggl\}
    $$
\end{lemma}

\begin{proof}
    $$
        p(x,y,z) = \prod_{i=1}^n p(x_i,y_i,z_i) =
        \prod_{i=1}^n \exp\{(1-x_i)(1-y_i)(1-z_i) \ln p_{000} + (1-x_i)(1-y_i)z_i \ln p_{001} + \ldots + x_i y_i z_i \ln p_{111}\} =
    $$
    $$
        =\exp \Biggl\{ \ln p_{000} \sum_{i=1}^n (1-x_i)(1-y_i)(1-z_i) +
        \ln p_{001} \sum_{i=1}^n (1-x_i)(1-y_i)z_i +
        \ln p_{010} \sum_{i=1}^n (1-x_i)y_i(1-z_i)+
    $$
    $$
        +\ln p_{011} \sum_{i=1}^n (1-x_i)y_i z_i+ \ln p_{100} \sum_{i=1}^n x_i(1-y_i)(1-z_i) + \ln p_{101} \sum_{i=1}^n x_i(1-y_i) z_i
        + \ln p_{110} \sum_{i=1}^n x_i y_i (1-z_i) + \ln p_{111} \sum_{i=1}^n x_i y_i z_i \Biggr\} =
    $$
    $$
        =\exp \Biggl\{ \ln p_{000} \Biggl(\sum_{i=1}^{n} 1 - \sum_{i=1}^{n}y_i - \sum_{i=1}^{n} x_i + \sum_{i=1}^{n} x_i y_i
        - \sum_{i=1}^{n} z_i + \sum_{i=1}^{n} y_i z_i + \sum_{i=1}^{n} x_i z_i - \sum_{i=1}^{n} x_i y_i z_i \Biggr) +
    $$
    $$
        + \ln p_{001} \Biggl( \sum_{i=1}^{n} z_i - \sum_{i=1}^{n} y_i z_i - \sum_{i=1}^{n} x_i z_i + \sum_{i=1}^{n} x_i y_i z_i \Biggr) +
        \ln p_{010} \Biggl(\sum_{i=1}^{n} y_i - \sum_{i=1}^{n} y_i z_i - \sum_{i=1}^{n} x_i y_i + \sum_{i=1}^{n} x_i y_i z_i\Biggr) +
    $$
    $$
        + \ln p_{011} \Biggl( \sum_{i=1}^n y_i z_i - \sum_{i=1}^{n} x_i y_i z_i \Biggr) +
        \ln p_{100} \Biggl( \sum_{i=1}^{n} x_i - \sum_{i=1}^{n} x_i z_i - \sum_{i=1}^{n} x_i y_i + \sum_{i=1}^{n} x_i y_i z_i  \Biggr) +
        \ln p_{101} \Biggl( \sum_{i=1}^{n} x_i z_i - \sum_{i=1}^{n} x_i y_i z_i \Biggr) +
    $$
    $$
        + \ln p_{110} \Biggl( \sum_{i=1}^{n} x_i y_i - \sum_{i=1}^{n} x_i y_i z_i \Biggr) +
        \ln p_{111} \sum_{i=1}^n x_i y_i z_i \Biggr\}=
    $$
    $$
        = \exp \Biggl\{ n \ln p_{000}\Biggr\}
        \exp \Biggl\{ \ln  \left(\dfrac{p_{001}p_{111}}{p_{011}p_{101}}  \dfrac{p_{010}p_{100}}{p_{000}p_{110}}\right) \sum_{i=1}^n x_i y_i z_i +
        \ln\left(\dfrac{p_{100}}{p_{000}}\right) \sum_{i=1}^{n} x_i + \ln\left(\dfrac{p_{010}}{p_{000}}\right) \sum_{i=1}^{n} y_i +
    $$
    $$
        + \ln\left(\dfrac{p_{001}}{p_{000}}\right) \sum_{i=1}^{n} z_i +\ln \left(\dfrac{p_{000}p_{110}}{p_{010}p_{100}}\right) \sum_{i=1}^n x_i y_i +
        \ln \left(\dfrac{p_{000}p_{101}}{p_{001}p_{100}}\right) \sum_{i=1}^n x_i z_i +
        \ln \left(\dfrac{p_{000}p_{011}}{p_{001}p_{010}}\right) \sum_{i=1}^n y_i z_i \Biggr\}
    $$
\end{proof}

Пусть $\theta = \ln  \left(\dfrac{p_{001}p_{111}}{p_{011}p_{101}}\right)$.
Можно проверить, что если выполнено одно из условий:
\begin{itemize}
    \item $X_1 \ci X_2 \mid X_3$
    \item $X_1 \ci X_3 \mid X_2$
    \item $X_2 \ci X_3 \mid X_1$
\end{itemize}
то параметр $\theta$ примет значение $\theta_0=0$ (а в обратную сторону?). В тесте структуры Неймана для проверки гипотезы для проверки гипотезы
$H: \theta = \theta_0$ против альтернативы $K: \theta \neq \theta_0$ используются следующие статистики:
$$
    U = \sum_{i=1}^n x_i y_i z_i,
    T_1 = \sum_{i=1}^n x_i y_i,
    T_2 = \sum_{i=1}^n x_i z_i,
    T_3 = \sum_{i=1}^n y_i z_i,
    T_4 = \sum_{i=1}^n x_i,
    T_5 = \sum_{i=1}^n y_i,
    T_6 = \sum_{i=1}^n z_i
$$
Для построения теста необходимо найти распределение:
$$
    P(U=u \mid T_1=t_1, T_2=t_2, T_3=t_3, T_4=t_4, T_5=t_5, T_6=t_6)
$$
Найдем совместное распределение вектора $(U,T_1,T_2,T_3,T_4,T_5,T_6)$.
\begin{lemma}
    $$P(U=u, T_1=t_1, T_2=t_2, T_3=t_3, T_4=t_4, T_5=t_5, T_6=t_6)=$$
    $$=M(u) \left(\dfrac{p_{001}p_{010}p_{100}p_{111}}{p_{000}p_{011}p_{101}p_{110}}\right)^u
        \left(\dfrac{p_{000} p_{110}}{p_{010} p_{100}}\right)^{t_1}\left(\dfrac{p_{000}p_{101}}{p_{001}p_{100}}\right)^{t_2}
        \left(\dfrac{p_{000}p_{011}}{p_{001}p_{010}}\right)^{t_3}\left(\dfrac{p_{100}}{p_{000}}\right)^{t_4}
        \left(\dfrac{p_{010}}{p_{000}}\right)^{t_5} \left(\dfrac{p_{001}}{p_{000}}\right)^{t_6} p_{000}^n$$
    где $$M(u)=\frac{n!}{u!(t_1-u)! (t_2-u)! (t_3-u)! (t_4-t_1-t_2+u)! (t_5-t_1-t_3+u)! (t_6 - t_2 - t_3 + u)! (n-u+t_1+t_2+t_3-t_4-t_5-t_6)!}$$
\end{lemma}
\begin{proof}
    $$
        P(U=u, T_1=t_1, T_2=t_2, T_3=t_3, T_4=t_4, T_5=t_5, T_6=t_6)=
    $$
    $$
        =P\biggl[\sum_{i=1}^n x_i y_i z_i=u, \sum_{i=1}^n x_i y_i=t_1, \sum_{i=1}^n x_i z_i=t_2,\sum_{i=1}^n y_i z_i=t_3,
            \sum_{i=1}^n x_i=t_4,\sum_{i=1}^n y_i=t_5, \sum_{i=1}^n z_i=t_6\biggr]=
    $$
    $$
        =P\biggl[\sum_{i=1}^n x_i y_i z_i=u, \sum_{i=1}^n x_i y_i (1- z_i)=t_1-u, \sum_{i=1}^n x_i (1-y_i) z_i=t_2-u, \sum_{i=1}^n (1-x_i) y_i z_i=t_3-u,
            $$
            $$
            \sum_{i=1}^{n} x_i(1-y_i)(1-z_i)=t_4-t_1-t_2+u, \sum_{i=1}^{n} (1-x_i)y_i(1-z_i)=t_5-t_1-t_3+u,
            $$
            $$
            \sum_{i=1}^{n} (1-x_i)(1-y_i)z_i = t_6 - t_2 - t_3 + u,
            \sum_{i=1}^n (1-x_i)(1-y_i)(1-z_i)=n-l+t_1+t_2+t_3-t_4-t_5-t_6)\biggr]=
    $$
    $$
        = M(u) p_{111}^u p_{110}^{t_1-u} p_{101}^{t_2-u} p_{011}^{t_3-u}
        p_{100}^{t_4-t_1-t_2+u} p_{010}^{t_5-t_1-t_3+u} p_{001}^{t_6 - t_2 - t_3 + u}
        p_{000}^{n-u+t_1+t_2+t_3-t_4-t_5-t_6}
        =
    $$
    $$
        = M(u) \left(\dfrac{p_{001}p_{010}p_{100}p_{111}}{p_{000}p_{011}p_{101}p_{110}}\right)^u
        \left(\dfrac{p_{000} p_{110}}{p_{010} p_{100}}\right)^{t_1}\left(\dfrac{p_{000}p_{101}}{p_{001}p_{100}}\right)^{t_2}
        \left(\dfrac{p_{000}p_{011}}{p_{001}p_{010}}\right)^{t_3}\left(\dfrac{p_{100}}{p_{000}}\right)^{t_4}
        \left(\dfrac{p_{010}}{p_{000}}\right)^{t_5} \left(\dfrac{p_{001}}{p_{000}}\right)^{t_6} p_{000}^n
    $$
\end{proof}

\begin{lemma}
    $$P_{\theta_0}(U=u \mid T_1=t_1, T_2=t_2, T_3=t_3, T_4=t_4, T_5=t_5, T_6=t_6)=\dfrac{M(u)}{\sum_{s} M(s)}$$
\end{lemma}
\begin{proof}
    $$P(T_1=t_1, T_2=t_2, T_3=t_3, T_4=t_4, T_5=t_5, T_6=t_6)=$$
    $$=\sum_{s} M(s) \left(\dfrac{p_{001}p_{010}p_{100}p_{111}}{p_{000}p_{011}p_{101}p_{110}}\right)^s
        \left(\dfrac{p_{000} p_{110}}{p_{010} p_{100}}\right)^{t_1}\left(\dfrac{p_{000}p_{101}}{p_{001}p_{100}}\right)^{t_2}
        \left(\dfrac{p_{000}p_{011}}{p_{001}p_{010}}\right)^{t_3}\left(\dfrac{p_{100}}{p_{000}}\right)^{t_4}
        \left(\dfrac{p_{010}}{p_{000}}\right)^{t_5} \left(\dfrac{p_{001}}{p_{000}}\right)^{t_6} p_{000}^n$$
    $$P(U=u \mid T_1=t_1, T_2=t_2, T_3=t_3, T_4=t_4, T_5=t_5, T_6=t_6)=$$
    $$=\dfrac{M(u) \left(\dfrac{p_{001}p_{010}p_{100}p_{111}}{p_{000}p_{011}p_{101}p_{110}}\right)^u
            \left(\dfrac{p_{000} p_{110}}{p_{010} p_{100}}\right)^{t_1}\left(\dfrac{p_{000}p_{101}}{p_{001}p_{100}}\right)^{t_2}
            \left(\dfrac{p_{000}p_{011}}{p_{001}p_{010}}\right)^{t_3}\left(\dfrac{p_{100}}{p_{000}}\right)^{t_4}
            \left(\dfrac{p_{010}}{p_{000}}\right)^{t_5} \left(\dfrac{p_{001}}{p_{000}}\right)^{t_6} p_{000}^n}{\sum_{s} M(s) \left(\dfrac{p_{001}p_{010}p_{100}p_{111}}{p_{000}p_{011}p_{101}p_{110}}\right)^s
            \left(\dfrac{p_{000} p_{110}}{p_{010} p_{100}}\right)^{t_1}\left(\dfrac{p_{000}p_{101}}{p_{001}p_{100}}\right)^{t_2}
            \left(\dfrac{p_{000}p_{011}}{p_{001}p_{010}}\right)^{t_3}\left(\dfrac{p_{100}}{p_{000}}\right)^{t_4}
            \left(\dfrac{p_{010}}{p_{000}}\right)^{t_5} \left(\dfrac{p_{001}}{p_{000}}\right)^{t_6} p_{000}^n}=$$
    $$=\dfrac{M(u) \left(\dfrac{p_{001}p_{010}p_{100}p_{111}}{p_{000}p_{011}p_{101}p_{110}}\right)^u}
        {\sum_{s} M(s) \left(\dfrac{p_{001}p_{010}p_{100}p_{111}}{p_{000}p_{011}p_{101}p_{110}}\right)^s}$$
        $$P_{\theta_0}(U=u \mid T_1=t_1, T_2=t_2, T_3=t_3, T_4=t_4, T_5=t_5, T_6=t_6)=\dfrac{M(u)}{\sum_{s} M(s)}$$
\end{proof}

\end{document}
