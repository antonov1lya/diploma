\begin{centering}
    \subsection{Тест на параметр трехмерного распределения Бернулли в экспоненциальной форме}\label{expon_form_section}
\end{centering}
Покажем вид трехмерного распределения Бернулли в экпоненциальной форме:
$$
    P(X=x,Y=y,Z=z) = p_{000}^{(1-x)(1-y)(1-z)} \ldots p_{111}^{x y z} =
$$
$$
    =
        \exp \Biggl\{\ln(p_{000}) +   \ln  \left(\dfrac{p_{001}p_{111}p_{010}p_{100}}{p_{011}p_{101}p_{000}p_{110}}\right)  xyz
     +   \ln\left(\dfrac{p_{100}}{p_{000}}\right) x +   \ln\left(\dfrac{p_{010}}{p_{000}}\right) y + $$
    $$    
    +  \ln\left(\dfrac{p_{001}}{p_{000}}\right) z
        +  \ln \left(\dfrac{p_{000}p_{110}}{p_{010}p_{100}}\right) xy +
         \ln \left(\dfrac{p_{000}p_{101}}{p_{001}p_{100}}\right) xz +
         \ln \left(\dfrac{p_{000}p_{011}}{p_{001}p_{010}}\right) yz \Biggr\}
    $$
Среди параметров, стоящих при статистиках $xyz,x,y,z,xy,xz,yz$ выделим параметр, связанный с условной независимостью.
\begin{theorem}
    Пусть $(X,Y,Z)^T$ -- случайный вектор, имеющий трехмерное распределение Бернулли, и 
    $\theta = \ln  \left(\dfrac{p_{001}p_{111}p_{010}p_{100}}{p_{011}p_{101}p_{000}p_{110}}\right)$.
    Если выполнено одно из условий:
    \begin{itemize}
        \item $X \ci Y \mid Z$
        \item $X \ci Z \mid Y$
        \item $Y \ci Z \mid X$
    \end{itemize}
    то параметр $\theta$ принимает значение $0$.
    \end{theorem}
    
    \begin{proof}
        Результаты теоремы $\ref{thm1}$ можно обобщить следующим образом:
        $$
        X \ci Z \mid Y \Leftrightarrow p_{000}p_{101}=p_{001}p_{100} \text{ и } p_{010}p_{111}=p_{011}p_{110}
        $$
        $$
        Y \ci Z \mid X \Leftrightarrow p_{000}p_{011}=p_{001}p_{010} \text { и } p_{100}p_{111}=p_{101}p_{110}
        $$
        \begin{enumerate}
            \item Пусть $X \ci Y \mid Z$, тогда по теореме \ref{thm1} выполнено:
            $p_{000}p_{110}=p_{010}p_{100}$ и  $p_{001}p_{111}=p_{011}p_{101}$. Отсюда следует, что
            $\theta=\ln(1)=0$.
            \item Пусть $X \ci Z \mid Y$, тогда из вышеприведенных соображений
            $p_{000}p_{101}=p_{001}p_{100}$ и $p_{010}p_{111}=p_{011}p_{110}$. Отсюда следует, что
            $\theta=\ln(1)=0$.
            \item Пусть $Y \ci Z \mid X$, тогда из вышеприведенных соображений
            $p_{000}p_{011}=p_{001}p_{010}$ и $p_{100}p_{111}=p_{101}p_{110}$. Отсюда следует, что
            $\theta=\ln(1)=0$.
        \end{enumerate}
    \end{proof}

    Таким образом, нулевое значение параметра
    $\theta$ является необходимым условием наличия условно независимой пары
    случайных величин в трехмерном распределении Бернулли.
    Для проверки гипотезы о равенстве параметра $\theta$ нулю используем 
    теорию РНМН тестов \cite{Lehmann1986} в многопараметрическом 
    экспоненциальном семействе. Пусть
    $$
        \begin{pmatrix}
            X_1 \\
            Y_1 \\
            Z_1
        \end{pmatrix},
        \begin{pmatrix}
            X_2 \\
            Y_2 \\
            Z_2
        \end{pmatrix}, \ldots,
        \begin{pmatrix}
            X_n \\
            Y_n \\
            Z_n
        \end{pmatrix}
    $$ повторная выборка из распределения случайного вектора $(X,Y,Z)^T$.
    Совместное распределение повторной выборки имеет вид:
    $$
    P(X_1=x_1,Y_1=y_1,Z_1=z_1,\ldots,X_n=x_n,Y_n=y_n,Z_n=z_n)=
    $$
    $$
    =\prod_{i=1}^n P(X_i=x_i,Y_i=y_i,Z_i=z_i) =
    $$
    $$
     =\exp \Biggl\{\ln(p_{000})n + \ln  \left(\dfrac{p_{001}p_{111}p_{010}p_{100}}{p_{011}p_{101}p_{000}p_{110}}\right) \sum_{i=1}^n x_i y_i z_i +$$
        $$ +
            \ln\left(\dfrac{p_{100}}{p_{000}}\right) \sum_{i=1}^{n} x_i + \ln\left(\dfrac{p_{010}}{p_{000}}\right) \sum_{i=1}^{n} y_i +
            \ln\left(\dfrac{p_{001}}{p_{000}}\right) \sum_{i=1}^{n} z_i +
        $$
        $$
            +\ln \left(\dfrac{p_{000}p_{110}}{p_{010}p_{100}}\right) \sum_{i=1}^n x_i y_i +
            \ln \left(\dfrac{p_{000}p_{101}}{p_{001}p_{100}}\right) \sum_{i=1}^n x_i z_i +
            \ln \left(\dfrac{p_{000}p_{011}}{p_{001}p_{010}}\right) \sum_{i=1}^n y_i z_i \Biggr\}
        $$
    Пусть 
    $$
        U = \sum_{i=1}^n X_i Y_i Z_i, \;
        T_1 = \sum_{i=1}^n X_i Y_i, \;
        T_2 = \sum_{i=1}^n X_i Z_i, \;
    $$
    $$
        T_3 = \sum_{i=1}^n Y_i Z_i, \;
        T_4 = \sum_{i=1}^n X_i, \;
        T_5 = \sum_{i=1}^n Y_i, \;
        T_6 = \sum_{i=1}^n Z_i \;
    $$
    Обозначим $T=(T_1,\ldots,T_6)$, $t=(t_1,\ldots,t_6)$, $\theta_0=0$.
    Тогда согласно \cite{Lehmann1986} РНМН тест уровня $\alpha$ проверки гипотезы $\theta=\theta_0$ против альтернативы $\theta \neq \theta_0$ имеет вид:
    $$
    \varphi^{\text{Theta}}(u,t)=\begin{cases}
        1, \; u<C_1(t) \text{ или } u>C_2(t)\\
        \gamma_i, \; u=C_i(t), \; i=1,2\\
        0, \; C_1(t)<u<C_2(t)
    \end{cases}
    $$
    где константы $C_i$ и $\gamma_i$ определяются из системы уравнений:
    $$
    \begin{cases}
        E_{\theta_0}[\varphi^{\text{Theta}}(U,T) \mid T=t]=\alpha \\
        E_{\theta_0}[U\varphi^{\text{Theta}}(U,T) \mid T=t]=\alpha E_{\theta_0}[U \mid T=t]
    \end{cases}
    $$
    Приведем распределение статистики $U$ при условии $T=t$.      
    \begin{lemma}\label{u_dist}
        Пусть $k_1(u)=u$, $k_2(u)=t_1-u$, $k_3(u)=t_2-u$, $k_4(u)=t_3-u$, $k_5(u)=t_4-t_1-t_2+u$, $k_6(u)=t_5-t_1-t_3+u$,
        $k_7(u)=t_6 - t_2 - t_3 + u$, $k_8(u)=n-u+t_1+t_2+t_3-t_4-t_5-t_6$.
        Тогда
        $$P_{\theta_0}(U=u \mid T=t)=\dfrac{(\prod_{i=1}^8 k_i(u)!)^{-1}}
            {\sum_{s\in \mathcal{D}} (\prod_{i=1}^8 k_i(s)!)^{-1}}$$
        где $\mathcal{D}=\{s \in \mathbb{Z}: 0\leq k_i(s) \leq n \text{ для всех } i=1\ldots,8\}$.
    \end{lemma}
    \begin{proof}
        Найдем совместное распределение статистик $(U,T_1,\ldots,T_6)$:
        $$
            P(U=u,T=t)=P(U=u, T_1=t_1, T_2=t_2, T_3=t_3, T_4=t_4, T_5=t_5, T_6=t_6)=
        $$
        $$
            =P\biggl(\sum_{i=1}^n X_i Y_i Z_i=u, \sum_{i=1}^n X_i Y_i=t_1, \sum_{i=1}^n X_i Z_i=t_2,\sum_{i=1}^n Y_i Z_i=t_3,
            $$
            $$
            \sum_{i=1}^n X_i=t_4,\sum_{i=1}^n Y_i=t_5, \sum_{i=1}^n Z_i=t_6\biggr)=
        $$
        $$
            =P\biggl(\sum_{i=1}^n X_i Y_i Z_i=u, \sum_{i=1}^n X_i Y_i (1- Z_i)=t_1-u, \sum_{i=1}^n X_i (1-Y_i) Z_i=t_2-u,
        $$
        $$
            \sum_{i=1}^n (1-X_i) Y_i Z_i=t_3-u,
            \sum_{i=1}^{n} X_i(1-Y_i)(1-Z_i)=t_4-t_1-t_2+u,
        $$
        $$
            \sum_{i=1}^{n} (1-X_i)Y_i(1-Z_i)=t_5-t_1-t_3+u,
            \sum_{i=1}^{n} (1-X_i)(1-Y_i)Z_i = t_6 - t_2 - t_3 + u,
        $$
        $$
            \sum_{i=1}^n (1-X_i)(1-Y_i)(1-Z_i)=n-u+t_1+t_2+t_3-t_4-t_5-t_6\biggr)
            = \frac{n!}{\prod_{i=1}^8 k_i(u)!} \times
        $$
        $$    
        \times p_{111}^u p_{110}^{t_1-u} p_{101}^{t_2-u} p_{011}^{t_3-u}
            p_{100}^{t_4-t_1-t_2+u} p_{010}^{t_5-t_1-t_3+u} p_{001}^{t_6 - t_2 - t_3 + u} 
            p_{000}^{n-u+t_1+t_2+t_3-t_4-t_5-t_6}
            $$
        Тогда условное распределение статистики $U$ при условии $T=t$ можно записать как:
        $$P(U=u \mid T=t)=\dfrac{P(U=u,T=t)}{P(T=t)}=
        \dfrac{P(U=u,T=t)}{\sum_{s \in \mathcal{D}} P(U=s,T=t)}=
        $$
        $$
        =\dfrac{(\prod_{i=1}^8 k_i(u)!)^{-1} \left(\dfrac{p_{001}p_{010}p_{100}p_{111}}{p_{000}p_{011}p_{101}p_{110}}\right)^u}
            {\sum_{s\in \mathcal{D}} (\prod_{i=1}^8 k_i(s)!)^{-1} \left(\dfrac{p_{001}p_{010}p_{100}p_{111}}{p_{000}p_{011}p_{101}p_{110}}\right)^s}$$
        При истинности гипотезы $\theta=\theta_0$ параметр $\dfrac{p_{001}p_{010}p_{100}p_{111}}{p_{000}p_{011}p_{101}p_{110}}=1$. Следовательно:
        $$P_{\theta_0}(U=u \mid T=t)=\dfrac{(\prod_{i=1}^8 k_i(u)!)^{-1}}
            {\sum_{s\in \mathcal{D}} (\prod_{i=1}^8 k_i(s)!)^{-1}}$$
    \end{proof}
    Так как $\varphi^{\text{Theta}}$ является тестом уровня
    $\alpha$ для проверки гипотезы $\theta=\theta_0$, где $\theta_0=0$,
    и из $X \ci Y \mid Z$ следует $\theta=0$, то 
    $\varphi^{\text{Theta}}$ является тестом уровня $\alpha$ для проверки
    гипотезы $h: X \ci Y \mid Z$.
    % Условную вероятность из леммы \ref{u_dist} можно эффективно вычислить на ЭВМ.
    % Пусть $f(i)=\sum_{j=1}^{i} \ln(j)$. Тогда значение условной вероятности представится в виде:
    % $$
    % \dfrac{\frac{1}{\prod_{i=1}^8 k_i(u)!}}{\sum_{s \in D} \frac{1}{\prod_{i=1}^8 k_i(s)!}}=
    % \dfrac{\exp \biggl\{ \ln \biggl( \frac{1}{\prod_{i=1}^8 k_i(u)!} \biggr) \biggr\}}
    % {\sum_{s \in D} \exp \biggl\{ \ln \biggl( \frac{1}{\prod_{i=1}^8 k_i(s)!} \biggr) \biggr\}}
    % = \dfrac{\exp \biggl\{ -\sum_{i=1}^8 \ln(k_i(u)!) \biggr\}}{\sum_{s \in D} \exp \biggl\{ -\sum_{i=1}^8 \ln(k_i(s)!) \biggr\}} =
    % $$
    % $$
    % = \dfrac{\exp \biggl\{ -\sum_{i=1}^8 f(k_i(u)) \biggr\}}{\sum_{s \in D} \exp \biggl\{ -\sum_{i=1}^8 f(k_i(s)) \biggr\}}
    % $$
    % Полученное выражение удобно с позиции того, что современные ЭВМ умеют вычислять функцию
    % $$
    % \varphi(x,i)=\dfrac{\exp\{x_i\}}{\sum_{j=1}^{n} \exp\{x_j\}}, \; x=(x_1,\ldots,x_n)
    % $$
    % За счет свойства
    % $$
    % \varphi(x,i)=\dfrac{\exp\{x_i\}}{\sum_{j=1}^{n} \exp\{x_j\}} = \dfrac{\exp\{x_i - C\}}{\sum_{j=1}^{n} \exp\{x_j - C\}}
    % , \text{ где } C=\max_{1\leq j \leq n} x_j
    % $$
    % удается избежать переполнения вещественного типа данных, связанного с экспонентой.