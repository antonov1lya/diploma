\subsection{РНМН тест проверки независимости в двумерном
распределении Бернулли}\label{bivariate_umpu}

% В следующем разделе будет показано, что проверку 
% условной независимости в трехмерном распределении Бернулли можно 
% свести к множественной проверке независимости в условных распределениях.
% Согласно работе \cite{Dai2013}, случайный вектор с 
% трехмерным распределением Бернулли
% при одной фиксированной компоненте имеет
% двумерное распределение Бернулли. Приведем теорию проверки независимости
% в двумерном распределении Бернулли.

% Пусть $(X,Y)^T$ -- случайный вектор, имеющий двумерное распределение Бернулли.
% При фиксированном $Z=z$:
% $$
% P(X=x,Y=y \mid Z=z) =
% \dfrac{p_{xyz}}{p_{00z}+p_{01z}+p_{10z}+p_{11z}} = q_{xy}
% $$
Приведем определение случайного вектора с 
двумерным распределением Бернулли \cite{Dai2013}.
\begin{definition}
    Случайный вектор $(X,Y)^T$ имеет двумерное распределение Бернулли,
    если множество его возможных значений:
    $$
        \begin{pmatrix}
            0 \\
            0
        \end{pmatrix},
        \begin{pmatrix}
            0 \\
            1
        \end{pmatrix},
        \begin{pmatrix}
            1 \\
            0
        \end{pmatrix},
        \begin{pmatrix}
            1 \\
            1
        \end{pmatrix}
    $$ и заданы $P(X=x,Y=y)=p_{xy} \geq 0,  \sum_{x=0}^1 \sum_{y=0}^1 p_{xy} =1$.
\end{definition}
Нами будут рассматриваться только случайные
векторы $(X,Y)^T$ с двумерным распределением Бернулли
в которых $p_{xy} > 0$ при всех
$x \in \{0,1\}$, $y\in \{0,1\}$.
% Таким образом, $(X,Y)^T$ при условии $Z=z$ имеет двумерное распределении Бернулли.
% Изложим теорию проверки независимости в двумерном распределении Бернулли,
% которая в \autoref{twos} будет использована для проверки условной независимости.
Запишем данное распределение в экспоненциальной форме:
$$
P(X=x,Y=y)=p_{00}^{(1-x)(1-y)}p_{01}^{(1-x)y}
p_{10}^{x(1-y)}p_{11}^{xy}=
$$
$$=\exp \left\{\ln(p_{00}) + 
     \ln \left(\dfrac{p_{10}}{p_{00}}\right) x
    +  \ln \left(\dfrac{p_{01}}{p_{00}}\right) y +
     \ln\left(\dfrac{p_{00}p_{11}}{p_{01}p_{10}}\right) xy
 \right\}
$$
Приведем теорему из работы \cite{Dai2013}.
\begin{theorem}
    Пусть $(X,Y)^T$ имеет двумерное распределение Бернулли,
    в котором $p_{xy} > 0$ при всех
    $x \in \{0,1\}$, $y\in \{0,1\}$. $X$ и $Y$ независимы тогда и только тогда, когда
$\theta=\ln\left(\dfrac{p_{00}p_{11}}{p_{01}p_{10}}\right)=0$.
\end{theorem}
Пусть
    $
        \begin{pmatrix}
            x_1 \\
            y_1 
        \end{pmatrix},
        \begin{pmatrix}
            x_2 \\
            y_2
        \end{pmatrix}, \ldots,
        \begin{pmatrix}
            x_n \\
            y_n
        \end{pmatrix}
    $
    реализация повторной выборки из распределения случайного вектора $(X,Y)^T$.
    Совместное распределение повторной выборки имеет вид:
$$
    P(X_1=x_1,Y_1=y_1,\ldots,X_n=x_n,Y_n=y_n)
    =\prod_{i=1}^n P(X_i=x_i,Y_i=y_i) =
    $$
    $$
    =\exp \left\{ \ln(p_{00})n + 
        \ln \left(\dfrac{p_{10}}{p_{00}}\right) \sum_{i=1}^n x_i 
        +\ln \left(\dfrac{p_{01}}{p_{00}}\right) \sum_{i=1}^{n} y_i   +
        \ln\left(\dfrac{p_{00}p_{11}}{p_{01}p_{10}}\right) \sum_{i=1}^n x_i y_i 
     \right\}
    $$
    Обозначим 
    $$
    u = \sum_{i=1}^n x_i y_i,\;
    t_1 = \sum_{i=1}^n x_i,\;
    t_2 = \sum_{i=1}^n y_i, \; t=(t_1,t_2)$$
    Согласно \cite{Lehmann1986} РНМН тест уровня $\alpha$ проверки гипотезы $H^{\text{Independence}}: \theta = 0$ против альтернативы $K^{\text{Independence}}: \theta \neq 0$ 
    имеет вид:
    $$
    \varphi^{\text{Independence}}(u,t)=\begin{cases}
        1, \; u<C_1(t) \text{ или } u>C_2(t)\\
        \gamma_i, \; u=C_i(t), \; i=1,2\\
        0, \; C_1(t)<u<C_2(t)
    \end{cases}
    $$
    где константы $C_i(t)$ и $\gamma_i(t)$ определяются из системы уравнений:
    $$
    \begin{cases}
        E_{\theta=0}(\varphi^{\text{Independence}}(U,T) \mid T=t)=\alpha \\
        E_{\theta=0}(U\varphi^{\text{Independence}}(U,T) \mid T=t)=\alpha E_{\theta=0}(U \mid T=t)
    \end{cases}
    $$
    Приведем распределение статистики $U$ при условии $T=t$.
\begin{lemma}\label{lm14}
    Пусть $k_1(u)=u$, $k_2(u)=t_1-u$, $k_3(u)=t_2-u$,\\
    $k_4(u)=n-t_1-t_2+u$.
        Тогда
        $$P_{\theta=0}(U=u \mid T=t)=\dfrac{(\prod_{i=1}^4 k_i(u)!)^{-1}}
            {\sum_{s\in \mathcal{D}} (\prod_{i=1}^4 k_i(s)!)^{-1}}$$
        где $\mathcal{D}=\{s \in \mathbb{Z}: 0\leq k_i(s) \leq n \text{ для всех } i=1\ldots,4\}$.
\end{lemma}
Доказательство \autoref{lm14} не приводится, поскольку оно полностью 
аналогично доказательству \autoref{u_dist}.

% Стоит отметить, что
% $
% \ln\left(\dfrac{q_{00}q_{11}}{q_{01}q_{10}}\right) =
% \ln\left(\dfrac{p_{00z}p_{11z}}{p_{01z}p_{10z}}\right)
% $. Поэтому, проверяя гипотезу о параметре
% $\ln\left(\dfrac{q_{00}q_{11}}{q_{01}q_{10}}\right)$ в условном распределении,
% мы проверяем гипотезу о параметре $\ln\left(\dfrac{p_{00z}p_{11z}}{p_{01z}p_{10z}}\right)$
% в трехмерном распределении Бернулли.

% \begin{proof}
%     $$P(U=u,T_1=t_1,T_2=t_2)=
%     P\left(\sum_{i=1}^n X_i Y_i=u,\sum_{i=1}^n X_i=t_1,
%     \sum_{i=1}^n Y_i=t_2\right)=$$
%     $$=P\biggl(
%         \sum_{i=1}^n X_i Y_i=u, \sum_{i=1}^n X_i (1-Y_i)=t_1-u,
%         \sum_{i=1}^n (1-X_i) Y_i=t_2-u,$$
%         $$
%         \sum_{i=1}^n (1-X_i) (1-Y_i)=n-t_1-t_2+u
%         \biggr)
%     =\dfrac{n!}{\prod_{i=1}^{4}k_i(u)!}
%     p_{11}^u p_{10}^{t_1-u} p_{01}^{t_2-u} p_{00}^{n-t_1-t_2+u}
%     $$
%     $$
%     P(U=u \mid T_1=t_1, T_2=t_2)=
%     \dfrac{(\prod_{i=1}^{4}k_i(u)!)^{-1}
%     \left(\dfrac{p_{00}p_{11}}{p_{01}p_{10}}\right)^u}
%     {\sum_{s}(\prod_{i=1}^{4}k_i(s)!)^{-1}
%     \left(\dfrac{p_{00}p_{11}}{p_{01}p_{10}}\right)^s}
%     $$
%     При истинности гипотезы $\theta=0$ параметр 
%     $\dfrac{p_{00}p_{11}}{p_{01}p_{10}}=1$. Тогда:
%     $$
%     P_{\theta=0}(U=u \mid T_1=t_1, T_2=t_2)=
%     \dfrac{(\prod_{i=1}^{4}k_i(u)!)^{-1}}
%     {\sum_{s}(\prod_{i=1}^{4}k_i(s)!)^{-1}}
%     $$
% \end{proof}